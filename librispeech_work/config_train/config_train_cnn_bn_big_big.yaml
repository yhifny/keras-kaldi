seed: 600
out_path: /work/asr_work


model:
    input_feat: fmllr
    input_dim: 40
    encoders:
        encoder_1:
            layers:            
                - type: batchnormalization            
                - type: dropout
                  value: 0.2  
                  
                - type: conv1d
                  units: 1024
                  activation: linear
                  strides: 1
                  kernel_width: 11
                - type: batchnormalization
                - type: activation
                  function: relu                  
                - type: dropout
                  value: 0.2
                  
                - type: conv1d
                  units: 1024
                  activation: linear
                  strides: 1
                  kernel_width: 11
                - type: batchnormalization
                - type: activation
                  function: relu                  
                - type: dropout
                  value: 0.2                 
                  
                - type: conv1d
                  units: 1024
                  activation: linear
                  strides: 1
                  kernel_width: 11
                - type: batchnormalization
                - type: activation
                  function: relu                  
                - type: dropout
                  value: 0.2 
                  
                - type: conv1d
                  units: 1024
                  activation: linear
                  strides: 1
                  kernel_width: 11
                - type: batchnormalization
                - type: activation
                  function: relu                  
                - type: dropout
                  value: 0.2                 
                - type: conv1d
                  units: 1024
                  activation: linear
                  strides: 1
                  kernel_width: 11
                - type: batchnormalization
                - type: activation
                  function: relu                  
                - type: dropout
                  value: 0.2 
                - type: conv1d
                  units: 1024
                  activation: linear
                  strides: 1
                  kernel_width: 11
                - type: batchnormalization
                - type: activation
                  function: relu                  
                - type: dropout
                  value: 0.2 
                - type: dense
                  units: 1024
                  activation: linear
                - type: batchnormalization                  
                - type: activation
                  function: relu                  
                  
    outputs:
        output_tri:
            layers:        
                - type: dense
                  units: 3480
                  activation: linear
                - type: batchnormalization                  
                - type: activation
                  name: output_tri
                  function: softmax              

        output_mono:
            layers:        
                - type: dense
                  units: 347  # start from 1 
                  activation: linear
                - type: batchnormalization                  
                - type: activation
                  name: output_mono   
                  function: softmax
                  
    seq2seq-encoder-decoder2:
        encoder-decoder_1:
            encoder:
                - lstm_units: 1024
            decoder:
                - lstm_units: 1024
                  units: 349 # mono + <s> + </s> 

loss_weights: {'output_tri' :1.0, 'output_mono': 1.0}                  
          
optimizer:          
    name: rmsprop
    ngpu: 2
    lr: 0.0004 # 1E-4
    rho: 0.95
    epsilon: 0.00000001
    batch_size: 16      